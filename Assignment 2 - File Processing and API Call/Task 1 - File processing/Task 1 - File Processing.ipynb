{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting location of our File Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Location of File Stack:\n",
      " C:\\Github\\Wright State University\\Assignment 2\\Task 1 - File processing\\Input_Data\\FS_L\\FS_L\\file_stack\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd += \"\\\\Input_Data\\\\FS_L\\\\FS_L\\\\file_stack\"\n",
    "print(\"\\nLocation of File Stack:\\n\",cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a list of files in our File Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of files in the File Stack:\n",
      " ['a_1.txt', 'a_10.txt', 'a_11.txt', 'a_12.txt', 'a_13.txt', 'a_14.txt', 'a_15.txt', 'a_16.txt', 'a_17.txt', 'a_18.txt', 'a_19.txt', 'a_2.txt', 'a_20.txt', 'a_21.txt', 'a_22.txt', 'a_23.txt', 'a_24.txt', 'a_25.txt', 'a_26.txt', 'a_27.txt', 'a_28.txt', 'a_29.txt', 'a_3.txt', 'a_30.txt', 'a_31.txt', 'a_32.txt', 'a_33.txt', 'a_34.txt', 'a_35.txt', 'a_36.txt', 'a_37.txt', 'a_38.txt', 'a_39.txt', 'a_4.txt', 'a_40.txt', 'a_41.txt', 'a_42.txt', 'a_43.txt', 'a_44.txt', 'a_45.txt', 'a_46.txt', 'a_47.txt', 'a_48.txt', 'a_49.txt', 'a_5.txt', 'a_50.txt', 'a_51.txt', 'a_52.txt', 'a_53.txt', 'a_54.txt', 'a_55.txt', 'a_56.txt', 'a_57.txt', 'a_58.txt', 'a_59.txt', 'a_6.txt', 'a_60.txt', 'a_61.txt', 'a_62.txt', 'a_63.txt', 'a_64.txt', 'a_65.txt', 'a_66.txt', 'a_67.txt', 'a_7.txt', 'a_8.txt', 'a_9.txt']\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir(cwd) if os.path.isfile(os.path.join(cwd,f))]\n",
    "files.remove(\".DS_Store\")\n",
    "print(\"\\nList of files in the File Stack:\\n\",files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying which files from CSV actually exist (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files to be modified:\n",
      " ['a_1.txt', 'a_6.txt', 'a_43.txt', 'a_12.txt', 'a_18.txt', 'a_5.txt', 'a_29.txt', 'a_37.txt', 'a_40.txt', 'a_54.txt', 'a_18.txt', 'a_10.txt']\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"Input_Data/FS_L/FS_L/list.csv\",\"r+\")\n",
    "csvdata = fp.read().splitlines(True)\n",
    "final = []\n",
    "count = 1\n",
    "for i in csvdata:\n",
    "    for j in i.split(\",\"):\n",
    "        if j[-1]!=\"\\n\":\n",
    "            curr = j + \".txt\"\n",
    "        else:\n",
    "            curr = j[:(len(j)-1)] + \".txt\"\n",
    "        count += 1\n",
    "        if curr in files:\n",
    "            final.append(curr)\n",
    "fp.close()\n",
    "del fp\n",
    "print(\"\\nFiles to be modified:\\n\",final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, for each file in 'final', Splitting into words, Capitalizing and Appending the word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Data:\n",
      " ['Deep learning is part of a broader family of machine learning methods based on learning data representations, as opposed to task-specific algorithms. Learning can be supervised, semi-supervised or unsupervised.']\n",
      "\n",
      "Modified Data:\n",
      " ['Deep Learning Is Part Of A Broader Family Of Machine Learning Methods Based On Learning Data Representations, As Opposed To Task-specific Algorithms. Learning Can Be Supervised, Semi-supervised Or Unsupervised.', '\\n29']\n",
      "\n",
      "Original Data:\n",
      " ['Deep learning architectures such as deep neural networks, deep belief networks and recurrent neural networks have been applied to fields including computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases superior to human experts.']\n",
      "\n",
      "Modified Data:\n",
      " ['Deep Learning Architectures Such As Deep Neural Networks, Deep Belief Networks And Recurrent Neural Networks Have Been Applied To Fields Including Computer Vision, Speech Recognition, Natural Language Processing, Audio Recognition, Social Network Filtering, Machine Translation, Bioinformatics, Drug Design, Medical Image Analysis, Material Inspection And Board Game Programs, Where They Have Produced Results Comparable To And In Some Cases Superior To Human Experts.', '\\n62']\n",
      "\n",
      "Original Data:\n",
      " ['Deep learning models are vaguely inspired by information processing and communication patterns in biological nervous systems yet have various differences from the structural and functional properties of biological brains, which make them incompatible with neuroscience evidences.']\n",
      "\n",
      "Modified Data:\n",
      " ['Deep Learning Models Are Vaguely Inspired By Information Processing And Communication Patterns In Biological Nervous Systems Yet Have Various Differences From The Structural And Functional Properties Of Biological Brains, Which Make Them Incompatible With Neuroscience Evidences.', '\\n36']\n",
      "\n",
      "Original Data:\n",
      " ['Most modern deep learning models are based on an artificial neural network, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.']\n",
      "\n",
      "Modified Data:\n",
      " ['Most Modern Deep Learning Models Are Based On An Artificial Neural Network, Although They Can Also Include Propositional Formulas Or Latent Variables Organized Layer-wise In Deep Generative Models Such As The Nodes In Deep Belief Networks And Deep Boltzmann Machines.', '\\n40']\n",
      "\n",
      "Original Data:\n",
      " ['Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors[13] and deep belief networks.']\n",
      "\n",
      "Modified Data:\n",
      " ['Deep Learning Algorithms Can Be Applied To Unsupervised Learning Tasks. This Is An Important Benefit Because Unlabeled Data Are More Abundant Than Labeled Data. Examples Of Deep Structures That Can Be Trained In An Unsupervised Manner Are Neural History Compressors[13] And Deep Belief Networks.', '\\n44']\n",
      "\n",
      "Original Data:\n",
      " ['The deep in deep learning refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path depth. The CAP is the chain of transformations from input to output.']\n",
      "\n",
      "Modified Data:\n",
      " ['The Deep In Deep Learning Refers To The Number Of Layers Through Which The Data Is Transformed. More Precisely, Deep Learning Systems Have A Substantial Credit Assignment Path Depth. The Cap Is The Chain Of Transformations From Input To Output.', '\\n40']\n",
      "\n",
      "Original Data:\n",
      " ['CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one as the output layer is also parameterized.']\n",
      "\n",
      "Modified Data:\n",
      " ['Caps Describe Potentially Causal Connections Between Input And Output. For A Feedforward Neural Network, The Depth Of The Caps Is That Of The Network And Is The Number Of Hidden Layers Plus One As The Output Layer Is Also Parameterized.', '\\n40']\n",
      "\n",
      "Original Data:\n",
      " [' For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[2] No universally agreed upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth > 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function.']\n",
      "\n",
      "Modified Data:\n",
      " ['For Recurrent Neural Networks, In Which A Signal May Propagate Through A Layer More Than Once, The Cap Depth Is Potentially Unlimited.[2] No Universally Agreed Upon Threshold Of Depth Divides Shallow Learning From Deep Learning, But Most Researchers Agree That Deep Learning Involves Cap Depth > 2. Cap Of Depth 2 Has Been Shown To Be A Universal Approximator In The Sense That It Can Emulate Any Function.', '\\n68']\n",
      "\n",
      "Original Data:\n",
      " [' Beyond that more layers do not add to the function approximator ability of the network. Deep models are able to extract better features than shallow models and hence, extra layers help in learning features.']\n",
      "\n",
      "Modified Data:\n",
      " ['Beyond That More Layers Do Not Add To The Function Approximator Ability Of The Network. Deep Models Are Able To Extract Better Features Than Shallow Models And Hence, Extra Layers Help In Learning Features.', '\\n34']\n",
      "\n",
      "Original Data:\n",
      " ['For supervised learning tasks, deep learning methods obviate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.']\n",
      "\n",
      "Modified Data:\n",
      " ['For Supervised Learning Tasks, Deep Learning Methods Obviate Feature Engineering, By Translating The Data Into Compact Intermediate Representations Akin To Principal Components, And Derive Layered Structures That Remove Redundancy In Representation.', '\\n31']\n",
      "\n",
      "Original Data:\n",
      " ['Deep Learning Algorithms Can Be Applied To Unsupervised Learning Tasks. This Is An Important Benefit Because Unlabeled Data Are More Abundant Than Labeled Data. Examples Of Deep Structures That Can Be Trained In An Unsupervised Manner Are Neural History Compressors[13] And Deep Belief Networks.\\n', '44']\n",
      "\n",
      "Modified Data:\n",
      " ['Deep Learning Algorithms Can Be Applied To Unsupervised Learning Tasks. This Is An Important Benefit Because Unlabeled Data Are More Abundant Than Labeled Data. Examples Of Deep Structures That Can Be Trained In An Unsupervised Manner Are Neural History Compressors[13] And Deep Belief Networks.', '44', '\\n45']\n",
      "\n",
      "Original Data:\n",
      " ['The term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986,[24][13] and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.']\n",
      "\n",
      "Modified Data:\n",
      " ['The Term Deep Learning Was Introduced To The Machine Learning Community By Rina Dechter In 1986,[24][13] And To Artificial Neural Networks By Igor Aizenberg And Colleagues In 2000, In The Context Of Boolean Threshold Neurons.', '\\n35']\n"
     ]
    }
   ],
   "source": [
    "for i in final:\n",
    "    path = cwd+\"\\\\\"+i\n",
    "    fpp = open(path,\"r+\")\n",
    "    data = fpp.read().splitlines(True)\n",
    "    count = 0\n",
    "    print(\"\\nOriginal Data:\\n\",data)\n",
    "    for line_num in range(len(data)):\n",
    "        words = data[line_num].split()\n",
    "        for word_num in range(len(words)):\n",
    "            words[word_num] = words[word_num].capitalize()\n",
    "            count += 1\n",
    "        line = \"\"\n",
    "        for j in range(len(words)):\n",
    "            if j==(len(words)-1):\n",
    "                line += words[j]\n",
    "            else:\n",
    "                line += (words[j]+\" \")\n",
    "        data[line_num] = line\n",
    "    data.append(\"\\n\"+str(count))\n",
    "    print(\"\\nModified Data:\\n\",data)\n",
    "    fpp.seek(0,0)\n",
    "    fpp.writelines(data)\n",
    "    fpp.close()\n",
    "    del fpp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
